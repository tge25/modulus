# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

hydra:
  job:
    chdir: False


## Main options
res_ckpt_filename: "/lustre/fsw/coreai_climate_earth2/corrdiff/training_output/diffusion_patch_twc_mvp1_test7/checkpoints/EDMPrecondSRV2.0.2690560.mdlus"   
  # Checkpoint filename for the generative model  
reg_ckpt_filename: "/lustre/fsw/coreai_climate_earth2/corrdiff/training_output/regression_twc_mvp1/checkpoints/UNet.0.880640.mdlus"
  # Checkpoint filename for the mean predictor model
image_outdir: "/lustre/fsw/coreai_climate_earth2/corrdiff/inferences/image_outdir"
  # Where to save the output images
seeds: "0-15"
  # Random seeds used for generation
class_idx: null  
  # Class label. Null is random
num_steps: 18
  # Number of sampling steps
sample_res: "full"
  # Sampling resolution
regression_only: false
  # regression only inference
diffusion_only: false
  # diffusion only inference
sampling_method: stochastic
  # Sampling method ["stochastic", "deterministic"]
seed_batch_size: 2
  # batch size across the seed dimension
force_fp16: true
  # Whether to force fp16 precision for the model. If false, it'll use the precision
  # specified upon training.
num_writer_workers: 1
  # number of workers to use for writing file
  # To support multiple workers a threadsafe version of the netCDF library must be used
use_torch_compile: False
  # whether to use torch.compile on the diffusion model
  # this will make the first time stamp generation very slow due to compilation overheads
  # but will significantly speed up subsequent inference runs

## Data options
## Data options
patch_shape_x: 448
patch_shape_y: 448
  # Patch size. Patch-based sampling will be utilized if these dimensions differ from 
  # img_shape_x and img_shape_y
overlap_pixels: 4 
  # Number of overlapping pixels between adjacent patches
boundary_pixels: 2
  # Number of boundary pixels to be cropped out. 2 is recommanded to address the boundary
  # artifact.
hr_mean_conditioning: true
  # High-res mean (regression's output) as additional condition
gridtype: "learnable"
N_grid_channels: 100
times:
  # winter storm
  - "2024011212f15"
  - "2024011400f00"
  - "2024011400f21"
  # random
  - "2024030518f03"
  - "2024051506f24"
  - "2024061212f12"
  # hurricane
  - "2024070400f00"
  - "2024070400f18"
  - "2024070800f00"
  - "2024070800f12"
  - "2024071006f00"
  - "2024071006f24"

## Weather data options
dataset:
  type: "twc_mvp1"
  ds_factor: 4
  train: False
  train_years: [2020, 2021, 2022, 2023,]
  valid_years: [2024]
  hrrr_window: [[1,1057], [4,1796]] # need dims to be divisible by 16 [[0,1024], [0,1024]]
  sample_shape: null #[1024, 1024] # 1024,1024 w/ 1 batch 4 hrrr channels and all era5 channels is 77gb
  train_test_split: False
  

## Deterministic sampler options
sigma_min: null
  # Lowest noise level
sigma_max: null
  # Highest noise level
rho: 7
  # Time step exponent
solver: euler
  # ODE solver [euler, heun]
discretization: "edm"
  # Time step discretization [vp, ve, iddpm, edm]
schedule: "linear"
  # noise schedule sigma(t) [vp, ve, linear]
scaling: null
  # Signal scaling s(t) [vp, none]
S_churn: 0
  # Stochasticity strength
S_min: 0
  # Stochasticity min noise level
S_max: .inf 
  # Stochasticity max noise level
S_noise: 1
  # Stochasticity noise inflation
